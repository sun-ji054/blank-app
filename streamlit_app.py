import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans # í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•´ import

# --- 1. ì•± ì„¤ì • ---
st.set_page_config(
    page_title="HUFS Data Dashboard",
    page_icon="ğŸ“",
    layout="wide"
)

# --- 2. ë‹¤êµ­ì–´ ì§€ì› í…ìŠ¤íŠ¸ (i18n) ---
# ëª¨ë“  UI í…ìŠ¤íŠ¸ë¥¼ ì´ê³³ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.
TEXTS = {
    'ko': {
        'lang_select': 'ì–¸ì–´ ì„ íƒ',
        'prof': 'ë‹´ë‹¹êµìˆ˜: ì´ë™í˜„',
        'school': 'Social Science & AIìœµí•©í•™ë¶€',
        'course': 'ì‚°ì—…ë°ì´í„°ì‹œê°í™”',
        'filter_header': 'ë°ì´í„° í•„í„°',
        'hour_slider': 'ì‹œê°„ ì„ íƒ:',
        'k_slider_label': 'í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (K):',
        'k_slider_help': 'K=1ì€ í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 2 ì´ìƒì„ ì„ íƒí•˜ë©´ K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.',
        'show_data_label': 'í•„í„°ë§ëœ ì›ë³¸ ë°ì´í„° ë³´ê¸°',
        'main_title': 'ğŸš• ë‰´ìš•ì‹œ Uber í”½ì—… ë°ì´í„° ì‹¤ì‹œê°„ ë¶„ì„',
        'main_desc': "ì´ ì•±ì€ 'ì‚°ì—…ë°ì´í„°ì‹œê°í™”' ìˆ˜ì—…ì„ ìœ„í•œ Streamlit ëŒ€ì‹œë³´ë“œ ì˜ˆì œì…ë‹ˆë‹¤. (ë‹¤êµ­ì–´ ë° í´ëŸ¬ìŠ¤í„°ë§ ì§€ì›)",
        'loading_text': 'ë°ì´í„° ë¡œë”© ì¤‘... (ì•½ 10ë§Œ ê±´)',
        'cluster_loading_text': 'í”½ì—… ìœ„ì¹˜ í´ëŸ¬ìŠ¤í„°ë§ ì¤‘...',
        'map_subheader_suffix': 'ì‹œê°„ëŒ€ì˜ Uber í”½ì—… ë§µ',
        'pickup_count': 'ì´ í”½ì—… ê±´ìˆ˜',
        'no_data_warn': 'í•´ë‹¹ ì‹œê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.',
        'hist_subheader': 'ì‹œê°„ëŒ€ë³„ ì „ì²´ í”½ì—… íšŸìˆ˜',
        'raw_data_subheader': 'ì›ë³¸ ë°ì´í„° (í•„í„°ë¨)',
        'data_load_error': 'ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ'
    },
    'en': {
        'lang_select': 'Language',
        'prof': 'Professor: Donghyun Lee',
        'school': 'Division of Social Science & AI',
        'course': 'Industrial Data Visualization',
        'filter_header': 'Data Filters',
        'hour_slider': 'Select Hour:',
        'k_slider_label': 'Number of Clusters (K):',
        'k_slider_help': 'K=1 means no clustering. Select 2 or more to run K-Means clustering.',
        'show_data_label': 'Show filtered raw data',
        'main_title': 'ğŸš• NYC Uber Pickups Real-time Analysis',
        'main_desc': 'This app is a Streamlit dashboard example for the "Industrial Data Visualization" class. (Multilingual & Clustering supported)',
        'loading_text': 'Loading data... (approx. 100k rows)',
        'cluster_loading_text': 'Clustering pickup locations...',
        'map_subheader_suffix': 'Uber Pickups Map',
        'pickup_count': 'Total Pickups',
        'no_data_warn': 'No data available for this hour.',
        'hist_subheader': 'Total Pickups by Hour',
        'raw_data_subheader': 'Raw Data (Filtered)',
        'data_load_error': 'Error loading data'
    }
}

# --- 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì–¸ì–´ ì„¤ì •) ---
if 'lang' not in st.session_state:
    st.session_state.lang = 'ko' # ê¸°ë³¸ê°’ì€ í•œêµ­ì–´

# --- 4. í—¬í¼ í•¨ìˆ˜ (ë°ì´í„° ë¡œë”©) ---
@st.cache_data
def load_data(nrows):
    DATA_URL = "https://s3-us-west-2.amazonaws.com/streamlit-demo-data/uber-raw-data-sep14.csv.gz"
    try:
        data = pd.read_csv(DATA_URL, nrows=nrows)
        data.rename(lambda x: str(x).lower(), axis='columns', inplace=True)
        data['date/time'] = pd.to_datetime(data['date/time'])
        data['hour'] = data['date/time'].dt.hour
        # st.mapì€ 'lat', 'lon' ì»¬ëŸ¼ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.
        data = data.rename(columns={'lat': 'lat', 'lon': 'lon'})
        return data
    except Exception as e:
        st.error(f"{TEXTS[st.session_state.lang]['data_load_error']}: {e}")
        return pd.DataFrame()

# í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 10ê°œ)
CLUSTER_COLORS = [
    "#FF0000", "#0000FF", "#00FF00", "#FFFF00", "#00FFFF",
    "#FF00FF", "#C0C0C0", "#800000", "#008000", "#000080"
]

# --- 5. ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    # ì–¸ì–´ ì„ íƒ
    lang_options = {'í•œêµ­ì–´': 'ko', 'English': 'en'}
    selected_lang_str = st.radio(
        label=TEXTS['ko']['lang_select'], # ë¼ë²¨ì€ ê³ ì •
        options=lang_options.keys(),
        horizontal=True,
    )
    st.session_state.lang = lang_options[selected_lang_str]
    lang = st.session_state.lang # í¸ì˜ë¥¼ ìœ„í•´ ë³€ìˆ˜ í• ë‹¹

    # ë¡œê³  ë° ìˆ˜ì—… ì •ë³´
    LOGO_URL = "https://www.hufs.ac.kr/sites/hufs/images/sub/simbol_list3.png"
    st.image(LOGO_URL)
    
    st.title("ìˆ˜ì—… ì •ë³´")
    st.markdown(
        f"""
        - **ëŒ€í•™êµ:** í•œêµ­ì™¸êµ­ì–´ëŒ€í•™êµ (HUFS)
        - **í•™ë¶€:** {TEXTS[lang]['school']}
        - **ìˆ˜ì—…:** {TEXTS[lang]['course']}
        - **{TEXTS[lang]['prof']}** """
    )
    
    st.divider() 
    
    st.header(TEXTS[lang]['filter_header'])
    
    # ì‹œê°„ í•„í„°
    hour_to_filter = st.slider(
        TEXTS[lang]['hour_slider'], 
        0, 23, 17
    )
    
    # í´ëŸ¬ìŠ¤í„° ê°œìˆ˜(K) í•„í„°
    k_clusters = st.slider(
        TEXTS[lang]['k_slider_label'],
        min_value=1,
        max_value=10,
        value=1, # ê¸°ë³¸ê°’ 1 (í´ëŸ¬ìŠ¤í„°ë§ ì—†ìŒ)
        help=TEXTS[lang]['k_slider_help']
    )
    
    # ì›ë³¸ ë°ì´í„° ë³´ê¸°
    show_raw_data = st.checkbox(TEXTS[lang]['show_data_label'])

# --- 6. ë©”ì¸ í™”ë©´ ---

# í˜„ì¬ ì–¸ì–´ ì„¤ì •(lang)ì— ë”°ë¼ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
lang = st.session_state.lang

st.title(TEXTS[lang]['main_title'])
st.markdown(TEXTS[lang]['main_desc'])

# ë°ì´í„° ë¡œë”©
with st.spinner(TEXTS[lang]['loading_text']):
    data = load_data(100000)

if not data.empty:
    # ì‹œê°„ í•„í„°ë§
    filtered_data = data[data['hour'] == hour_to_filter].copy() # .copy()ë¡œ Warning ë°©ì§€

    # ë§µ ì œëª©
    st.subheader(f"{hour_to_filter}:00 {TEXTS[lang]['map_subheader_suffix']}")
    st.write(f"{TEXTS[lang]['pickup_count']}: **{len(filtered_data)}**")

    # ë§µ ì‹œê°í™” (í´ëŸ¬ìŠ¤í„°ë§ í¬í•¨)
    if not filtered_data.empty:
        if k_clusters > 1:
            # K=2 ì´ìƒì´ë©´ K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
            with st.spinner(TEXTS[lang]['cluster_loading_text']):
                # ìœ„ë„(lat)ì™€ ê²½ë„(lon)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§
                kmeans = KMeans(n_clusters=k_clusters, n_init=10, random_state=42)
                filtered_data['cluster'] = kmeans.fit_predict(filtered_data[['lat', 'lon']])
                
                # í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ì— ë”°ë¼ ìƒ‰ìƒ ë§¤í•‘
                # (10ê°œê°€ ë„˜ëŠ” í´ëŸ¬ìŠ¤í„°ëŠ” ìƒ‰ìƒì´ ë°˜ë³µë©ë‹ˆë‹¤)
                filtered_data['color'] = filtered_data['cluster'].apply(
                    lambda x: CLUSTER_COLORS[x % len(CLUSTER_COLORS)]
                )
                
                # 'color' ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ ì§€ë„ì— ìƒ‰ìƒ í‘œì‹œ
                st.map(filtered_data, color='color')
                
        else:
            # K=1ì´ë©´ (ê¸°ë³¸ê°’) í´ëŸ¬ìŠ¤í„°ë§ ì—†ì´ í‘œì‹œ
            st.map(filtered_data)
            
    else:
        st.warning(TEXTS[lang]['no_data_warn'])

    # ì‹œê°„ëŒ€ë³„ í”½ì—… í†µê³„ (ë§‰ëŒ€ ì°¨íŠ¸)
    st.subheader(TEXTS[lang]['hist_subheader'])
    hist_values = np.histogram(data['hour'], bins=24, range=(0, 24))[0]
    hist_df = pd.DataFrame({'hour': range(24), 'pickups': hist_values})
    st.bar_chart(hist_df.set_index('hour'))

    # ì›ë³¸ ë°ì´í„° í‘œì‹œ
    if show_raw_data:
        st.subheader(TEXTS[lang]['raw_data_subheader'])
        st.dataframe(filtered_data, use_container_width=True)
else:
    st.error(TEXTS[lang]['data_load_error'])
